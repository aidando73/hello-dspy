{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install \"sglang[all]\"; pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n",
    "\n",
    "pip install -U torch transformers accelerate trl peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import random\n",
    "from dspy.datasets import DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Banking77 dataset.\n",
    "CLASSES = load_dataset(\"PolyAI/banking77\", split=\"train\", trust_remote_code=True).features['label'].names\n",
    "kwargs = dict(fields=(\"text\", \"label\"), input_keys=(\"text\",), split=\"train\", trust_remote_code=True)\n",
    "print(CLASSES)\n",
    "# Load the first 2000 examples from the dataset, and assign a hint to each *training* example.\n",
    "raw_data = [\n",
    "    dspy.Example(x, label=CLASSES[x.label]).with_inputs(\"text\")\n",
    "    for x in DataLoader().from_huggingface(dataset_name=\"PolyAI/banking77\", **kwargs)[:1000]\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77,\n",
       " ['activate_my_card',\n",
       "  'age_limit',\n",
       "  'apple_pay_or_google_pay',\n",
       "  'atm_support',\n",
       "  'automatic_top_up',\n",
       "  'balance_not_updated_after_bank_transfer',\n",
       "  'balance_not_updated_after_cheque_or_cash_deposit',\n",
       "  'beneficiary_not_allowed',\n",
       "  'cancel_transfer',\n",
       "  'card_about_to_expire'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CLASSES), CLASSES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'text': 'What if there is an error on the exchange rate?'}) (input_keys={'text'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_trainset = [dspy.Example(text=x.text).with_inputs(\"text\") for x in raw_data[:500]]\n",
    "\n",
    "unlabeled_trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "classify = dspy.ChainOfThought(f\"text -> label: Literal{CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.clients.lm_local import LocalProvider\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "student_lm_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "student_lm = dspy.LM(model=f\"openai/local:{student_lm_name}\", provider=LocalProvider(), max_tokens=2000)\n",
    "teacher_lm = dspy.LM('openai/gpt-4o-mini', max_tokens=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_classify = classify.deepcopy()\n",
    "student_classify.set_lm(student_lm)\n",
    "\n",
    "teacher_classify = classify.deepcopy()\n",
    "teacher_classify.set_lm(teacher_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 18:28:59 INFO dspy.teleprompt.bootstrap_finetune: Preparing the student and teacher programs...\n",
      "2025/03/13 18:28:59 INFO dspy.teleprompt.bootstrap_finetune: Bootstrapping data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 500.00 / 500 (100.0%): 100%|██████████| 500/500 [00:00<00:00, 787.34it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 18:29:00 INFO dspy.evaluate.evaluate: Average Metric: 500 / 500 (100.0%)\n",
      "2025/03/13 18:29:00 INFO dspy.teleprompt.bootstrap_finetune: Preparing the train data...\n",
      "2025/03/13 18:29:01 INFO dspy.teleprompt.bootstrap_finetune: Using 500 data points for fine-tuning the model: openai/local:meta-llama/Llama-3.2-1B-Instruct\n",
      "2025/03/13 18:29:01 INFO dspy.teleprompt.bootstrap_finetune: Starting LM fine-tuning...\n",
      "2025/03/13 18:29:01 INFO dspy.teleprompt.bootstrap_finetune: 1 fine-tuning job(s) to start\n",
      "2025/03/13 18:29:01 INFO dspy.teleprompt.bootstrap_finetune: Starting 1 fine-tuning job(s)...\n",
      "2025/03/13 18:29:01 INFO dspy.teleprompt.bootstrap_finetune: Calling lm.kill() on the LM to be fine-tuned to free up resources. This won't have any effect if the LM is not running.\n",
      "2025/03/13 18:29:01 INFO dspy.clients.lm_local: No running server to kill.\n",
      "2025/03/13 18:29:01 INFO dspy.clients.lm_local: Starting local training, will save to /home/coder/.dspy_cache/finetune/4f6b8f1c7529aa66_qf1spu_meta-llama-Llama-3.2-1B-Instruct_2025-03-13_18-29-01\n",
      "2025/03/13 18:29:03 ERROR dspy.clients.lm: Failed to import trl.trainer.sft_trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.image_processing_utils because of the following error (look up to see its traceback):\n",
      "operator torchvision::nms does not exist\n",
      "2025/03/13 18:29:03 INFO dspy.teleprompt.bootstrap_finetune: Job 1/1 is done\n",
      "2025/03/13 18:29:03 INFO dspy.teleprompt.bootstrap_finetune: Updating the student program with the fine-tuned LMs...\n",
      "2025/03/13 18:29:03 INFO dspy.teleprompt.bootstrap_finetune: BootstrapFinetune has finished compiling the student program\n"
     ]
    }
   ],
   "source": [
    "optimizer = dspy.BootstrapFinetune(num_threads=16)  # if you *do* have labels, pass metric=your_metric here!\n",
    "dspy.settings.experimental = True\n",
    "classify_ft = optimizer.compile(student_classify, teacher=teacher_classify, trainset=unlabeled_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RuntimeError' object has no attribute 'launch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassify_ft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RuntimeError' object has no attribute 'launch'"
     ]
    }
   ],
   "source": [
    "classify_ft.get_lm().launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
