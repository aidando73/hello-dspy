{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install \"sglang[all]\"; pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n",
    "\n",
    "pip install -U torch transformers accelerate trl peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/dev/hello-dspy/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activate_my_card', 'age_limit', 'apple_pay_or_google_pay', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_acceptance', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_not_working', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'card_swallowed', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_card_payment', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'exchange_charge', 'exchange_rate', 'exchange_via_app', 'extra_charge_on_statement', 'failed_transfer', 'fiat_currency_support', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment?', 'supported_cards_and_currencies', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_card_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'visa_or_mastercard', 'why_verify_identity', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import random\n",
    "from dspy.datasets import DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Banking77 dataset.\n",
    "CLASSES = load_dataset(\"PolyAI/banking77\", split=\"train\", trust_remote_code=True).features['label'].names\n",
    "kwargs = dict(fields=(\"text\", \"label\"), input_keys=(\"text\",), split=\"train\", trust_remote_code=True)\n",
    "print(CLASSES)\n",
    "# Load the first 2000 examples from the dataset, and assign a hint to each *training* example.\n",
    "raw_data = [\n",
    "    dspy.Example(x, label=CLASSES[x.label]).with_inputs(\"text\")\n",
    "    for x in DataLoader().from_huggingface(dataset_name=\"PolyAI/banking77\", **kwargs)[:1000]\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77,\n",
       " ['activate_my_card',\n",
       "  'age_limit',\n",
       "  'apple_pay_or_google_pay',\n",
       "  'atm_support',\n",
       "  'automatic_top_up',\n",
       "  'balance_not_updated_after_bank_transfer',\n",
       "  'balance_not_updated_after_cheque_or_cash_deposit',\n",
       "  'beneficiary_not_allowed',\n",
       "  'cancel_transfer',\n",
       "  'card_about_to_expire'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CLASSES), CLASSES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'text': 'What if there is an error on the exchange rate?'}) (input_keys={'text'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_trainset = [dspy.Example(text=x.text).with_inputs(\"text\") for x in raw_data[:500]]\n",
    "\n",
    "unlabeled_trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "classify = dspy.ChainOfThought(f\"text -> label: Literal{CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.clients.lm_local import LocalProvider\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "student_lm_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "student_lm = dspy.LM(model=f\"openai/local:{student_lm_name}\", provider=LocalProvider(), max_tokens=2000)\n",
    "teacher_lm = dspy.LM('openai/gpt-4o-mini', max_tokens=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_classify = classify.deepcopy()\n",
    "student_classify.set_lm(student_lm)\n",
    "\n",
    "teacher_classify = classify.deepcopy()\n",
    "teacher_classify.set_lm(teacher_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 18:31:12 INFO dspy.teleprompt.bootstrap_finetune: Preparing the student and teacher programs...\n",
      "2025/03/13 18:31:12 INFO dspy.teleprompt.bootstrap_finetune: Bootstrapping data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 500.00 / 500 (100.0%): 100%|██████████| 500/500 [00:01<00:00, 257.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 18:31:14 INFO dspy.evaluate.evaluate: Average Metric: 500 / 500 (100.0%)\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: Preparing the train data...\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: Using 500 data points for fine-tuning the model: openai/local:meta-llama/Llama-3.2-1B-Instruct\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: Starting LM fine-tuning...\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: 1 fine-tuning job(s) to start\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: Starting 1 fine-tuning job(s)...\n",
      "2025/03/13 18:31:14 INFO dspy.teleprompt.bootstrap_finetune: Calling lm.kill() on the LM to be fine-tuned to free up resources. This won't have any effect if the LM is not running.\n",
      "2025/03/13 18:31:16 INFO dspy.clients.lm_local: No running server to kill.\n",
      "2025/03/13 18:31:16 INFO dspy.clients.lm_local: Starting local training, will save to /home/coder/.dspy_cache/finetune/4f6b8f1c7529aa66_n2et63_meta-llama-Llama-3.2-1B-Instruct_2025-03-13_18-31-16\n",
      "2025/03/13 18:31:18 ERROR dspy.clients.lm: Failed to import trl.trainer.sft_trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.image_processing_utils because of the following error (look up to see its traceback):\n",
      "operator torchvision::nms does not exist\n",
      "2025/03/13 18:31:18 INFO dspy.teleprompt.bootstrap_finetune: Job 1/1 is done\n",
      "2025/03/13 18:31:18 INFO dspy.teleprompt.bootstrap_finetune: Updating the student program with the fine-tuned LMs...\n",
      "2025/03/13 18:31:18 INFO dspy.teleprompt.bootstrap_finetune: BootstrapFinetune has finished compiling the student program\n"
     ]
    }
   ],
   "source": [
    "optimizer = dspy.BootstrapFinetune(num_threads=16)  # if you *do* have labels, pass metric=your_metric here!\n",
    "dspy.settings.experimental = True\n",
    "classify_ft = optimizer.compile(student_classify, teacher=teacher_classify, trainset=unlabeled_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RuntimeError' object has no attribute 'launch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassify_ft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RuntimeError' object has no attribute 'launch'"
     ]
    }
   ],
   "source": [
    "classify_ft.get_lm().launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
