{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/374362034103955121', creation_time=1741686562632, experiment_id='374362034103955121', last_update_time=1741686562632, lifecycle_stage='active', name='DSPy', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"DSPy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'tokens': ['Peter', 'Blackburn'], 'expected_extracted_people': ['Peter', 'Blackburn']}) (input_keys={'tokens'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, Any, List\n",
    "import dspy\n",
    "\n",
    "def load_conll_dataset() -> dict:\n",
    "    \"\"\"\n",
    "    Loads the CoNLL-2003 dataset into train, validation, and test splits.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dataset splits with keys 'train', 'validation', and 'test'.\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Use a temporary Hugging Face cache directory for compatibility with certain hosted notebook\n",
    "        # environments that don't support the default Hugging Face cache directory\n",
    "        os.environ[\"HF_DATASETS_CACHE\"] = temp_dir\n",
    "        return load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "def extract_people_entities(data_row: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts entities referring to people from a row of the CoNLL-2003 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_row (Dict[str, Any]): A row from the dataset containing tokens and NER tags.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of tokens tagged as people.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        token\n",
    "        for token, ner_tag in zip(data_row[\"tokens\"], data_row[\"ner_tags\"])\n",
    "        if ner_tag in (1, 2)  # CoNLL entity codes 1 and 2 refer to people\n",
    "    ]\n",
    "\n",
    "def prepare_dataset(data_split, start: int, end: int) -> List[dspy.Example]:\n",
    "    \"\"\"\n",
    "    Prepares a sliced dataset split for use with DSPy.\n",
    "    \n",
    "    Args:\n",
    "        data_split: The dataset split (e.g., train or test).\n",
    "        start (int): Starting index of the slice.\n",
    "        end (int): Ending index of the slice.\n",
    "    \n",
    "    Returns:\n",
    "        List[dspy.Example]: List of DSPy Examples with tokens and expected labels.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        dspy.Example(\n",
    "            tokens=row[\"tokens\"],\n",
    "            expected_extracted_people=extract_people_entities(row)\n",
    "        ).with_inputs(\"tokens\")\n",
    "        for row in data_split.select(range(start, end))\n",
    "    ]\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_conll_dataset()\n",
    "\n",
    "# Prepare the training and test sets\n",
    "train_set = prepare_dataset(dataset[\"train\"], 0, 50)\n",
    "test_set = prepare_dataset(dataset[\"test\"], 0, 200)\n",
    "\n",
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class PeopleExtraction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
    "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
    "    \"\"\"\n",
    "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
    "    extracted_people: list[str] = dspy.OutputField(desc=\"all tokens referring to specific people extracted from the tokenized text\")\n",
    "\n",
    "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(model=\"openai/gpt-4o-mini\")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_correctness_metric(example: dspy.Example, prediction: dspy.Prediction, trace=None) -> bool:\n",
    "    \"\"\"\n",
    "    Computes correctness of entity extraction predictions.\n",
    "    \n",
    "    Args:\n",
    "        example (dspy.Example): The dataset example containing expected people entities.\n",
    "        prediction (dspy.Prediction): The prediction from the DSPy people extraction program.\n",
    "        trace: Optional trace object for debugging.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if predictions match expectations, False otherwise.\n",
    "    \"\"\"\n",
    "    return prediction.extracted_people == example.expected_extracted_people\n",
    "\n",
    "evaluate_correctness = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=extraction_correctness_metric,\n",
    "    num_threads=24,\n",
    "    display_progress=True,\n",
    "    display_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 181.00 / 200 (90.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:16<00:00, 12.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:25:55 INFO dspy.evaluate.evaluate: Average Metric: 181 / 200 (90.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>expected_extracted_people</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>extracted_people</th>\n",
       "      <th>extraction_correctness_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
       "      <td>[CHINA]</td>\n",
       "      <td>The tokens provided do not contain any specific names of people. T...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>The tokens \"Nadim\" and \"Ladki\" refer to specific individuals. They...</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any references to specific peop...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any specific names of people. T...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In the provided tokens, \"China\" and \"Uzbekistan\" are the only toke...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>The tokenized text mentions \"David Campese,\" who is a specific per...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The text mentions \"the 34-year-old winger,\" which refers to a spec...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>The tokens contain references to specific people, namely \"Campese\"...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>The tokenized text mentions \"Andrew\" as a specific person. It is t...</td>\n",
       "      <td>[Andrew]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any specific names of people. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‚úîÔ∏è [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    tokens  \\\n",
       "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
       "1                                                           [Nadim, Ladki]   \n",
       "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
       "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
       "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
       "..                                                                     ...   \n",
       "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
       "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
       "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
       "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
       "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
       "\n",
       "    expected_extracted_people  \\\n",
       "0                     [CHINA]   \n",
       "1              [Nadim, Ladki]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "195          [David, Campese]   \n",
       "196                        []   \n",
       "197    [Campese, Rob, Andrew]   \n",
       "198           [Campo, Andrew]   \n",
       "199                        []   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    The tokens provided do not contain any specific names of people. T...   \n",
       "1    The tokens \"Nadim\" and \"Ladki\" refer to specific individuals. They...   \n",
       "2    The provided tokens do not contain any references to specific peop...   \n",
       "3    The provided tokens do not contain any specific names of people. T...   \n",
       "4    In the provided tokens, \"China\" and \"Uzbekistan\" are the only toke...   \n",
       "..                                                                     ...   \n",
       "195  The tokenized text mentions \"David Campese,\" who is a specific per...   \n",
       "196  The text mentions \"the 34-year-old winger,\" which refers to a spec...   \n",
       "197  The tokens contain references to specific people, namely \"Campese\"...   \n",
       "198  The tokenized text mentions \"Andrew\" as a specific person. It is t...   \n",
       "199  The provided tokens do not contain any specific names of people. I...   \n",
       "\n",
       "           extracted_people extraction_correctness_metric  \n",
       "0                        []                                \n",
       "1            [Nadim, Ladki]                     ‚úîÔ∏è [True]  \n",
       "2                        []                     ‚úîÔ∏è [True]  \n",
       "3                        []                     ‚úîÔ∏è [True]  \n",
       "4                        []                     ‚úîÔ∏è [True]  \n",
       "..                      ...                           ...  \n",
       "195        [David, Campese]                     ‚úîÔ∏è [True]  \n",
       "196                      []                     ‚úîÔ∏è [True]  \n",
       "197  [Campese, Rob, Andrew]                     ‚úîÔ∏è [True]  \n",
       "198                [Andrew]                                \n",
       "199                      []                     ‚úîÔ∏è [True]  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "90.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=24c25c79828f4423931dacf53164a4d5&amp;experiment_id=374362034103955121&amp;trace_id=ec0246f88f2b48808b77328976445bd3&amp;experiment_id=374362034103955121&amp;trace_id=eb69ad4fab1a42d8ac7069fa70f94e31&amp;experiment_id=374362034103955121&amp;trace_id=b8715e69b68d4065b3c5e1c9f4a99dc3&amp;experiment_id=374362034103955121&amp;trace_id=34f6b5f258494943a82537a7a58deb1b&amp;experiment_id=374362034103955121&amp;trace_id=7c548b24117948e1a0e518a34ff29482&amp;experiment_id=374362034103955121&amp;trace_id=7d8e095e8c6c4571963ba7552ebf6662&amp;experiment_id=374362034103955121&amp;trace_id=bac79b58ccbf4c668a14802c9273ade1&amp;experiment_id=374362034103955121&amp;trace_id=a5c17e28603f4a248f4e2d6a9ead63be&amp;experiment_id=374362034103955121&amp;trace_id=85e8c3cd96ca42ce831d992d3b8510b2&amp;experiment_id=374362034103955121&amp;version=2.20.3\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=24c25c79828f4423931dacf53164a4d5), Trace(request_id=ec0246f88f2b48808b77328976445bd3), Trace(request_id=eb69ad4fab1a42d8ac7069fa70f94e31), Trace(request_id=b8715e69b68d4065b3c5e1c9f4a99dc3), Trace(request_id=34f6b5f258494943a82537a7a58deb1b), Trace(request_id=7c548b24117948e1a0e518a34ff29482), Trace(request_id=7d8e095e8c6c4571963ba7552ebf6662), Trace(request_id=bac79b58ccbf4c668a14802c9273ade1), Trace(request_id=a5c17e28603f4a248f4e2d6a9ead63be), Trace(request_id=85e8c3cd96ca42ce831d992d3b8510b2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_correctness(people_extractor, devset=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 181.00 / 200 (90.5%): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:28:54 INFO dspy.evaluate.evaluate: Average Metric: 181 / 200 (90.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÉ View run extractor_evaluation at: http://localhost:5000/#/experiments/374362034103955121/runs/9a305735ced747d897fb77fc4d195825\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/374362034103955121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=5c10a2b4f89644d7a536b70156d872dc&amp;experiment_id=374362034103955121&amp;trace_id=32931affce454ed3b981a375fe413238&amp;experiment_id=374362034103955121&amp;trace_id=277468f416374168b96d987c1e3df3aa&amp;experiment_id=374362034103955121&amp;trace_id=07473c288e54446da47170017f9514e3&amp;experiment_id=374362034103955121&amp;trace_id=1db84fe235924be2a7db1e52ea3326af&amp;experiment_id=374362034103955121&amp;trace_id=cf5694d0169b439d87b544d2e72d7a56&amp;experiment_id=374362034103955121&amp;trace_id=c92a86792ecd40d79be059197dbaa69f&amp;experiment_id=374362034103955121&amp;trace_id=071e979540774766a2b13241d1d19d88&amp;experiment_id=374362034103955121&amp;trace_id=6020059fb36a4911b15b5790dae8942d&amp;experiment_id=374362034103955121&amp;trace_id=a449c79c49db4d42a076b8da80d96333&amp;experiment_id=374362034103955121&amp;version=2.20.3\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=5c10a2b4f89644d7a536b70156d872dc), Trace(request_id=32931affce454ed3b981a375fe413238), Trace(request_id=277468f416374168b96d987c1e3df3aa), Trace(request_id=07473c288e54446da47170017f9514e3), Trace(request_id=1db84fe235924be2a7db1e52ea3326af), Trace(request_id=cf5694d0169b439d87b544d2e72d7a56), Trace(request_id=c92a86792ecd40d79be059197dbaa69f), Trace(request_id=071e979540774766a2b13241d1d19d88), Trace(request_id=6020059fb36a4911b15b5790dae8942d), Trace(request_id=a449c79c49db4d42a076b8da80d96333)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"extractor_evaluation\"):\n",
    "    evaluate_correctness = dspy.Evaluate(\n",
    "        devset=test_set,\n",
    "        metric=extraction_correctness_metric,\n",
    "        num_threads=24,\n",
    "        display_progress=True,\n",
    "        # To record the outputs and detailed scores to MLflow\n",
    "        return_all_scores=True,\n",
    "        return_outputs=True,\n",
    "    )\n",
    "\n",
    "    # Evaluate the program as usual\n",
    "    aggregated_score, outputs, all_scores = evaluate_correctness(people_extractor)\n",
    "\n",
    "    # Log the aggregated score\n",
    "    mlflow.log_metric(\"exact_match\", aggregated_score)\n",
    "    # Log the detailed evaluation results as a table\n",
    "    mlflow.log_table(\n",
    "        {\n",
    "            \"Tokens\": [example.tokens for example in test_set],\n",
    "            \"Expected\": [example.expected_extracted_people for example in test_set],\n",
    "            \"Predicted\": outputs,\n",
    "            \"Exact match\": all_scores,\n",
    "        },\n",
    "        artifact_file=\"eval_results.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 25\n",
      "minibatch: False\n",
      "num_candidates: 19\n",
      "valset size: 40\n",
      "\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/19\n",
      "Bootstrapping set 2/19\n",
      "Bootstrapping set 3/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:02<00:18,  2.01s/it]"
     ]
    }
   ],
   "source": [
    "mipro_optimizer = dspy.MIPROv2(\n",
    "    metric=extraction_correctness_metric,\n",
    "    auto=\"medium\",\n",
    ")\n",
    "optimized_people_extractor = mipro_optimizer.compile(\n",
    "    people_extractor,\n",
    "    trainset=train_set,\n",
    "    max_bootstrapped_demos=4,\n",
    "    requires_permission_to_run=False,\n",
    "    minibatch=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
