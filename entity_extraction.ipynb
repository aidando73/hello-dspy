{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/374362034103955121', creation_time=1741686562632, experiment_id='374362034103955121', last_update_time=1741686562632, lifecycle_stage='active', name='DSPy', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"DSPy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'tokens': ['Peter', 'Blackburn'], 'expected_extracted_people': ['Peter', 'Blackburn']}) (input_keys={'tokens'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, Any, List\n",
    "import dspy\n",
    "\n",
    "def load_conll_dataset() -> dict:\n",
    "    \"\"\"\n",
    "    Loads the CoNLL-2003 dataset into train, validation, and test splits.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dataset splits with keys 'train', 'validation', and 'test'.\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Use a temporary Hugging Face cache directory for compatibility with certain hosted notebook\n",
    "        # environments that don't support the default Hugging Face cache directory\n",
    "        os.environ[\"HF_DATASETS_CACHE\"] = temp_dir\n",
    "        return load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "def extract_people_entities(data_row: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts entities referring to people from a row of the CoNLL-2003 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_row (Dict[str, Any]): A row from the dataset containing tokens and NER tags.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of tokens tagged as people.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        token\n",
    "        for token, ner_tag in zip(data_row[\"tokens\"], data_row[\"ner_tags\"])\n",
    "        if ner_tag in (1, 2)  # CoNLL entity codes 1 and 2 refer to people\n",
    "    ]\n",
    "\n",
    "def prepare_dataset(data_split, start: int, end: int) -> List[dspy.Example]:\n",
    "    \"\"\"\n",
    "    Prepares a sliced dataset split for use with DSPy.\n",
    "    \n",
    "    Args:\n",
    "        data_split: The dataset split (e.g., train or test).\n",
    "        start (int): Starting index of the slice.\n",
    "        end (int): Ending index of the slice.\n",
    "    \n",
    "    Returns:\n",
    "        List[dspy.Example]: List of DSPy Examples with tokens and expected labels.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        dspy.Example(\n",
    "            tokens=row[\"tokens\"],\n",
    "            expected_extracted_people=extract_people_entities(row)\n",
    "        ).with_inputs(\"tokens\")\n",
    "        for row in data_split.select(range(start, end))\n",
    "    ]\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_conll_dataset()\n",
    "\n",
    "# Prepare the training and test sets\n",
    "train_set = prepare_dataset(dataset[\"train\"], 0, 50)\n",
    "test_set = prepare_dataset(dataset[\"test\"], 0, 200)\n",
    "\n",
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class PeopleExtraction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
    "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
    "    \"\"\"\n",
    "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
    "    extracted_people: list[str] = dspy.OutputField(desc=\"all tokens referring to specific people extracted from the tokenized text\")\n",
    "\n",
    "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(model=\"openai/gpt-4o-mini\")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_correctness_metric(example: dspy.Example, prediction: dspy.Prediction, trace=None) -> bool:\n",
    "    \"\"\"\n",
    "    Computes correctness of entity extraction predictions.\n",
    "    \n",
    "    Args:\n",
    "        example (dspy.Example): The dataset example containing expected people entities.\n",
    "        prediction (dspy.Prediction): The prediction from the DSPy people extraction program.\n",
    "        trace: Optional trace object for debugging.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if predictions match expectations, False otherwise.\n",
    "    \"\"\"\n",
    "    return prediction.extracted_people == example.expected_extracted_people\n",
    "\n",
    "evaluate_correctness = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=extraction_correctness_metric,\n",
    "    num_threads=24,\n",
    "    display_progress=True,\n",
    "    display_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 181.00 / 200 (90.5%): 100%|██████████| 200/200 [00:16<00:00, 12.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:25:55 INFO dspy.evaluate.evaluate: Average Metric: 181 / 200 (90.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>expected_extracted_people</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>extracted_people</th>\n",
       "      <th>extraction_correctness_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
       "      <td>[CHINA]</td>\n",
       "      <td>The tokens provided do not contain any specific names of people. T...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>The tokens \"Nadim\" and \"Ladki\" refer to specific individuals. They...</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any references to specific peop...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any specific names of people. T...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In the provided tokens, \"China\" and \"Uzbekistan\" are the only toke...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>The tokenized text mentions \"David Campese,\" who is a specific per...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The text mentions \"the 34-year-old winger,\" which refers to a spec...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>The tokens contain references to specific people, namely \"Campese\"...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>The tokenized text mentions \"Andrew\" as a specific person. It is t...</td>\n",
       "      <td>[Andrew]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The provided tokens do not contain any specific names of people. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    tokens  \\\n",
       "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
       "1                                                           [Nadim, Ladki]   \n",
       "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
       "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
       "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
       "..                                                                     ...   \n",
       "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
       "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
       "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
       "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
       "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
       "\n",
       "    expected_extracted_people  \\\n",
       "0                     [CHINA]   \n",
       "1              [Nadim, Ladki]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "195          [David, Campese]   \n",
       "196                        []   \n",
       "197    [Campese, Rob, Andrew]   \n",
       "198           [Campo, Andrew]   \n",
       "199                        []   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    The tokens provided do not contain any specific names of people. T...   \n",
       "1    The tokens \"Nadim\" and \"Ladki\" refer to specific individuals. They...   \n",
       "2    The provided tokens do not contain any references to specific peop...   \n",
       "3    The provided tokens do not contain any specific names of people. T...   \n",
       "4    In the provided tokens, \"China\" and \"Uzbekistan\" are the only toke...   \n",
       "..                                                                     ...   \n",
       "195  The tokenized text mentions \"David Campese,\" who is a specific per...   \n",
       "196  The text mentions \"the 34-year-old winger,\" which refers to a spec...   \n",
       "197  The tokens contain references to specific people, namely \"Campese\"...   \n",
       "198  The tokenized text mentions \"Andrew\" as a specific person. It is t...   \n",
       "199  The provided tokens do not contain any specific names of people. I...   \n",
       "\n",
       "           extracted_people extraction_correctness_metric  \n",
       "0                        []                                \n",
       "1            [Nadim, Ladki]                     ✔️ [True]  \n",
       "2                        []                     ✔️ [True]  \n",
       "3                        []                     ✔️ [True]  \n",
       "4                        []                     ✔️ [True]  \n",
       "..                      ...                           ...  \n",
       "195        [David, Campese]                     ✔️ [True]  \n",
       "196                      []                     ✔️ [True]  \n",
       "197  [Campese, Rob, Andrew]                     ✔️ [True]  \n",
       "198                [Andrew]                                \n",
       "199                      []                     ✔️ [True]  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "90.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=24c25c79828f4423931dacf53164a4d5&amp;experiment_id=374362034103955121&amp;trace_id=ec0246f88f2b48808b77328976445bd3&amp;experiment_id=374362034103955121&amp;trace_id=eb69ad4fab1a42d8ac7069fa70f94e31&amp;experiment_id=374362034103955121&amp;trace_id=b8715e69b68d4065b3c5e1c9f4a99dc3&amp;experiment_id=374362034103955121&amp;trace_id=34f6b5f258494943a82537a7a58deb1b&amp;experiment_id=374362034103955121&amp;trace_id=7c548b24117948e1a0e518a34ff29482&amp;experiment_id=374362034103955121&amp;trace_id=7d8e095e8c6c4571963ba7552ebf6662&amp;experiment_id=374362034103955121&amp;trace_id=bac79b58ccbf4c668a14802c9273ade1&amp;experiment_id=374362034103955121&amp;trace_id=a5c17e28603f4a248f4e2d6a9ead63be&amp;experiment_id=374362034103955121&amp;trace_id=85e8c3cd96ca42ce831d992d3b8510b2&amp;experiment_id=374362034103955121&amp;version=2.20.3\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=24c25c79828f4423931dacf53164a4d5), Trace(request_id=ec0246f88f2b48808b77328976445bd3), Trace(request_id=eb69ad4fab1a42d8ac7069fa70f94e31), Trace(request_id=b8715e69b68d4065b3c5e1c9f4a99dc3), Trace(request_id=34f6b5f258494943a82537a7a58deb1b), Trace(request_id=7c548b24117948e1a0e518a34ff29482), Trace(request_id=7d8e095e8c6c4571963ba7552ebf6662), Trace(request_id=bac79b58ccbf4c668a14802c9273ade1), Trace(request_id=a5c17e28603f4a248f4e2d6a9ead63be), Trace(request_id=85e8c3cd96ca42ce831d992d3b8510b2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_correctness(people_extractor, devset=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 181.00 / 200 (90.5%): 100%|██████████| 200/200 [00:01<00:00, 113.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:28:54 INFO dspy.evaluate.evaluate: Average Metric: 181 / 200 (90.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏃 View run extractor_evaluation at: http://localhost:5000/#/experiments/374362034103955121/runs/9a305735ced747d897fb77fc4d195825\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/374362034103955121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=5c10a2b4f89644d7a536b70156d872dc&amp;experiment_id=374362034103955121&amp;trace_id=32931affce454ed3b981a375fe413238&amp;experiment_id=374362034103955121&amp;trace_id=277468f416374168b96d987c1e3df3aa&amp;experiment_id=374362034103955121&amp;trace_id=07473c288e54446da47170017f9514e3&amp;experiment_id=374362034103955121&amp;trace_id=1db84fe235924be2a7db1e52ea3326af&amp;experiment_id=374362034103955121&amp;trace_id=cf5694d0169b439d87b544d2e72d7a56&amp;experiment_id=374362034103955121&amp;trace_id=c92a86792ecd40d79be059197dbaa69f&amp;experiment_id=374362034103955121&amp;trace_id=071e979540774766a2b13241d1d19d88&amp;experiment_id=374362034103955121&amp;trace_id=6020059fb36a4911b15b5790dae8942d&amp;experiment_id=374362034103955121&amp;trace_id=a449c79c49db4d42a076b8da80d96333&amp;experiment_id=374362034103955121&amp;version=2.20.3\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=5c10a2b4f89644d7a536b70156d872dc), Trace(request_id=32931affce454ed3b981a375fe413238), Trace(request_id=277468f416374168b96d987c1e3df3aa), Trace(request_id=07473c288e54446da47170017f9514e3), Trace(request_id=1db84fe235924be2a7db1e52ea3326af), Trace(request_id=cf5694d0169b439d87b544d2e72d7a56), Trace(request_id=c92a86792ecd40d79be059197dbaa69f), Trace(request_id=071e979540774766a2b13241d1d19d88), Trace(request_id=6020059fb36a4911b15b5790dae8942d), Trace(request_id=a449c79c49db4d42a076b8da80d96333)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"extractor_evaluation\"):\n",
    "    evaluate_correctness = dspy.Evaluate(\n",
    "        devset=test_set,\n",
    "        metric=extraction_correctness_metric,\n",
    "        num_threads=24,\n",
    "        display_progress=True,\n",
    "        # To record the outputs and detailed scores to MLflow\n",
    "        return_all_scores=True,\n",
    "        return_outputs=True,\n",
    "    )\n",
    "\n",
    "    # Evaluate the program as usual\n",
    "    aggregated_score, outputs, all_scores = evaluate_correctness(people_extractor)\n",
    "\n",
    "    # Log the aggregated score\n",
    "    mlflow.log_metric(\"exact_match\", aggregated_score)\n",
    "    # Log the detailed evaluation results as a table\n",
    "    mlflow.log_table(\n",
    "        {\n",
    "            \"Tokens\": [example.tokens for example in test_set],\n",
    "            \"Expected\": [example.expected_extracted_people for example in test_set],\n",
    "            \"Predicted\": outputs,\n",
    "            \"Exact match\": all_scores,\n",
    "        },\n",
    "        artifact_file=\"eval_results.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 25\n",
      "minibatch: False\n",
      "num_candidates: 19\n",
      "valset size: 40\n",
      "\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/03/13 14:30:01 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/19\n",
      "Bootstrapping set 2/19\n",
      "Bootstrapping set 3/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:10,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:06,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 5/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:06,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 6/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 531.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 7/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00, 610.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 8/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 598.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 9/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 728.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 10/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 11/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 12/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 675.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 13/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 14/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 1076.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 15/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00, 908.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 16/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00, 736.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 17/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 1089.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 18/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 724.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 19/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 918.09it/s]\n",
      "2025/03/13 14:30:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/03/13 14:30:18 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:30:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
      "Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 1: In a critical situation where food safety regulations are being debated in the European Union, it is essential to identify and extract the names of key individuals involved in the discussions. Given a list of tokenized words from news articles, your task is to extract any contiguous tokens that refer to specific people mentioned in the context of British lamb and mad cow disease regulations. Carefully analyze the tokens and provide a list of extracted names, as this information is vital for understanding the stakeholders in this high-stakes health policy matter. Remember to output the names as separate tokens and include your reasoning for each extraction decision.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a named entity recognition expert. Your task is to extract contiguous tokens that refer specifically to individuals from a list of string tokens. Carefully analyze the tokens and provide a list of extracted tokens that represent specific people. Ensure that you do not combine multiple tokens into a single value and include reasoning that explains your extraction process step by step.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given a list of tokenized text related to critical discussions on food safety in the European Union, extract and identify any contiguous tokens that refer to specific individuals involved in these discussions. This task is crucial as it may influence public health policies and regulatory measures. Be thorough in your analysis and provide reasoning for your extraction decisions. Output a list of tokens that represent these individuals, ensuring that no multiple tokens are combined into a single value.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 4: In a critical situation where accurate identification of key officials is essential for formulating health policies regarding food safety in the European Union, extract contiguous tokens referring to specific people from the provided list of string tokens. Ensure that only names of identifiable individuals are included in the output list, avoiding any general terms or organizational references. Your task is crucial for ensuring informed decision-making in the context of public health and safety.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 5: In a critical situation where food safety regulations are being debated, you are tasked with identifying key individuals mentioned in a series of news articles regarding British lamb and mad cow disease. Extract contiguous tokens that refer to specific people from the provided list of tokenized text. Ensure your output is a list of tokens, and do not combine multiple tokens into a single value. This information is vital for understanding who is influencing health policies and advisories in this high-stakes context.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 6: Analyze the provided list of string tokens for any contiguous sequences that refer to specific individuals. Ensure to extract each name as separate tokens without merging them. Provide a detailed reasoning process that explains the criteria used for identifying the names, and output the list of extracted tokens representing the identified individuals.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 7: In a critical situation where public health is at stake, you are tasked with analyzing a dataset of European Union news related to food safety, specifically focusing on British lamb and mad cow disease. Your goal is to extract any references to specific individuals mentioned in the tokenized text. Carefully examine the tokens provided and identify any contiguous sequences that refer to identifiable people. Output a list of these extracted tokens, ensuring that you do not combine multiple tokens into a single value. If no specific individuals are found, clearly state this in your reasoning and return an empty list for extracted people.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 8: Given a list of tokenized text strings, identify and extract contiguous tokens that refer to specific individuals. Provide a list of these tokens without combining them into single values. Additionally, include reasoning that explains the decision-making process behind the extraction.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 9: Analyze the provided tokenized text and identify any contiguous sequences of tokens that refer to identifiable individuals. Extract these names while ensuring that each token of a name remains separate in the output list. Provide a clear reasoning for your extraction process, detailing how you determined which tokens correspond to specific people.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 10: Given a list of tokenized text, identify and extract contiguous sequences of tokens that refer to specific individuals. Provide a detailed reasoning for each extraction decision, explaining how you determined which tokens represent a person's name. The output should consist of a list of extracted names and the corresponding reasoning for each extraction.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 11: Analyze the provided list of tokenized strings to identify and extract any contiguous sequences of tokens that refer to specific individuals. For each identified name, provide reasoning that explains the extraction process step by step. If no names are found, indicate that as well. Output the extracted names as a list of tokens, ensuring that multiple tokens referring to a single person are not combined into a single value.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 12: Analyze the provided list of tokenized strings to identify and extract contiguous sequences of tokens that refer to specific individuals. Ensure that each name is output as a separate token and not combined with others. Provide a reasoning statement that outlines the steps taken to determine which tokens represent a person's name. Your output should include a list of extracted names and the corresponding reasoning for the extraction process.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 13: You are a text analysis expert. Your task is to extract contiguous tokens that refer to specific individuals from a provided list of string tokens. Carefully analyze the tokens to identify any names, and ensure that each name is represented as separate tokens in your output. Provide reasoning for your extraction process, explaining whether identifiable people are present or not.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 14: In a critical situation where public health is at stake due to food safety concerns related to British lamb and mad cow disease, you are tasked with extracting references to specific individuals from a provided list of tokenized text. Your goal is to identify and output only the contiguous tokens that refer to these individuals. This extraction is vital for understanding the roles of key officials and representatives in the discussions surrounding health policies. Remember, do not combine multiple tokens into a single value; output each name as a separate token.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Analyze the provided list of tokenized strings and identify any contiguous tokens that specifically refer to individuals. Clearly state the reasoning behind your identification process and output a list of those extracted tokens. Remember, only include tokens that directly denote people and do not merge multiple tokens into a single entry.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 16: Analyze the provided list of tokens and identify any tokens that specifically refer to identifiable individuals. Extract these tokens as a list, ensuring that each token remains separate and is not combined with others. Document your reasoning step-by-step to clarify how you determined which tokens represent people.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 17: You are a named entity recognition expert. Your task is to extract contiguous tokens referring to specific people from a list of string tokens. Analyze the tokens step by step and output a list of extracted names without combining them into a single value.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: 18: Analyze the provided list of tokenized text and extract any contiguous tokens that specifically refer to identifiable individuals. For each token sequence, apply step-by-step reasoning to determine if they represent names of people. Ensure that you output a list of extracted tokens without combining them into a single entity. If no identifiable individuals are found, return an empty list.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/03/13 14:32:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 25 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 40 (92.5%): 100%|██████████| 40/40 [00:10<00:00,  3.65it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:32:37 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
      "2025/03/13 14:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 92.5\n",
      "\n",
      "/Users/aidand/dev/hello-dspy/env/lib/python3.10/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/03/13 14:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:13<00:00,  2.91it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:32:51 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 97.5\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5]\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:32:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 40 (75.0%): 100%|██████████| 40/40 [00:16<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:33:07 INFO dspy.evaluate.evaluate: Average Metric: 30 / 40 (75.0%)\n",
      "2025/03/13 14:33:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/03/13 14:33:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0]\n",
      "2025/03/13 14:33:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:33:07 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:33:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:10<00:00,  3.79it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:33:18 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:33:18 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
      "2025/03/13 14:33:18 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0]\n",
      "2025/03/13 14:33:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:33:18 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:33:18 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.00 / 40 (92.5%): 100%|██████████| 40/40 [00:16<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:33:34 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
      "2025/03/13 14:33:34 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 15', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/03/13 14:33:34 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5]\n",
      "2025/03/13 14:33:34 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:33:34 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:33:34 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:14<00:00,  2.73it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:33:49 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
      "2025/03/13 14:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0]\n",
      "2025/03/13 14:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.00 / 40 (80.0%): 100%|██████████| 40/40 [00:12<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:02 INFO dspy.evaluate.evaluate: Average Metric: 32 / 40 (80.0%)\n",
      "2025/03/13 14:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/03/13 14:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0]\n",
      "2025/03/13 14:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:14<00:00,  2.77it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:16 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:34:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 12'].\n",
      "2025/03/13 14:34:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0]\n",
      "2025/03/13 14:34:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:16 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:15<00:00,  2.63it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:32 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:34:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
      "2025/03/13 14:34:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5]\n",
      "2025/03/13 14:34:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:32 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.00 / 40 (82.5%): 100%|██████████| 40/40 [00:11<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:43 INFO dspy.evaluate.evaluate: Average Metric: 33 / 40 (82.5%)\n",
      "2025/03/13 14:34:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/03/13 14:34:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5]\n",
      "2025/03/13 14:34:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:12<00:00,  3.16it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:55 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5]\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 4957.07it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:34:55 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5]\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:34:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 40 (85.0%): 100%|██████████| 40/40 [00:14<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:09 INFO dspy.evaluate.evaluate: Average Metric: 34 / 40 (85.0%)\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 85.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 13'].\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0]\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 5003.94it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:09 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5]\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:12<00:00,  3.20it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:22 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:35:22 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 17'].\n",
      "2025/03/13 14:35:22 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0]\n",
      "2025/03/13 14:35:22 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:22 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:22 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:13<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:35 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:35:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 6', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/03/13 14:35:35 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0]\n",
      "2025/03/13 14:35:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:35 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:10<00:00,  3.66it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:46 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:35:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 13', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/03/13 14:35:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5]\n",
      "2025/03/13 14:35:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:46 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:46 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.00 / 40 (77.5%): 100%|██████████| 40/40 [00:13<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:35:59 INFO dspy.evaluate.evaluate: Average Metric: 31 / 40 (77.5%)\n",
      "2025/03/13 14:35:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 16'].\n",
      "2025/03/13 14:35:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5]\n",
      "2025/03/13 14:35:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:35:59 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:35:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:12<00:00,  3.27it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:36:12 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:36:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 9', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/03/13 14:36:12 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5]\n",
      "2025/03/13 14:36:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:36:12 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:36:12 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.00 / 40 (90.0%): 100%|██████████| 40/40 [00:11<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:36:23 INFO dspy.evaluate.evaluate: Average Metric: 36 / 40 (90.0%)\n",
      "2025/03/13 14:36:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 90.0 with parameters ['Predictor 0: Instruction 17', 'Predictor 0: Few-Shot Set 13'].\n",
      "2025/03/13 14:36:23 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0]\n",
      "2025/03/13 14:36:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:36:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:36:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.00 / 40 (77.5%): 100%|██████████| 40/40 [00:13<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:36:36 INFO dspy.evaluate.evaluate: Average Metric: 31 / 40 (77.5%)\n",
      "2025/03/13 14:36:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.5 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/03/13 14:36:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0, 77.5]\n",
      "2025/03/13 14:36:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:36:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:36:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 22 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:11<00:00,  3.55it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:36:48 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/03/13 14:36:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/03/13 14:36:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0, 77.5, 95.0]\n",
      "2025/03/13 14:36:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:36:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:36:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.00 / 40 (90.0%): 100%|██████████| 40/40 [00:13<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:37:01 INFO dspy.evaluate.evaluate: Average Metric: 36 / 40 (90.0%)\n",
      "2025/03/13 14:37:01 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 90.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/03/13 14:37:01 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0, 77.5, 95.0, 90.0]\n",
      "2025/03/13 14:37:01 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:37:01 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:37:01 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 24 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 4431.15it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:37:02 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/03/13 14:37:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/03/13 14:37:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0, 77.5, 95.0, 90.0, 97.5]\n",
      "2025/03/13 14:37:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:37:02 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:37:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 25 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.00 / 40 (82.5%): 100%|██████████| 40/40 [00:16<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 14:37:18 INFO dspy.evaluate.evaluate: Average Metric: 33 / 40 (82.5%)\n",
      "2025/03/13 14:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.5 with parameters ['Predictor 0: Instruction 18', 'Predictor 0: Few-Shot Set 11'].\n",
      "2025/03/13 14:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 97.5, 75.0, 95.0, 92.5, 95.0, 80.0, 95.0, 97.5, 82.5, 97.5, 97.5, 85.0, 97.5, 95.0, 95.0, 97.5, 77.5, 97.5, 90.0, 77.5, 95.0, 90.0, 97.5, 82.5]\n",
      "2025/03/13 14:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/03/13 14:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/03/13 14:37:18 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 97.5!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mipro_optimizer = dspy.MIPROv2(\n",
    "    metric=extraction_correctness_metric,\n",
    "    auto=\"medium\",\n",
    ")\n",
    "optimized_people_extractor = mipro_optimizer.compile(\n",
    "    people_extractor,\n",
    "    trainset=train_set,\n",
    "    max_bootstrapped_demos=4,\n",
    "    requires_permission_to_run=False,\n",
    "    minibatch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-13T14:37:18.514253]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `tokens` (list[str]): tokenized text\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `extracted_people` (list[str]): all tokens referring to specific people extracted from the tokenized text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "{tokens}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "{extracted_people}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Analyze the provided list of tokenized text and extract any contiguous tokens that specifically refer to identifiable individuals. For each token sequence, apply step-by-step reasoning to determine if they represent names of people. Ensure that you output a list of extracted tokens without combining them into a single entity. If no identifiable individuals are found, return an empty list.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "[\"He\", \"said\", \"further\", \"scientific\", \"study\", \"was\", \"required\", \"and\", \"if\", \"it\", \"was\", \"found\", \"that\", \"action\", \"was\", \"needed\", \"it\", \"should\", \"be\", \"taken\", \"by\", \"the\", \"European\", \"Union\", \".\"]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The tokens provided do not contain any specific names of individuals or identifiable people. The only reference to a group is \"European Union,\" which refers to an organization rather than a specific person. Therefore, there are no extracted people from the given tokens.\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "[]\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "[\"BRUSSELS\", \"1996-08-22\"]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The provided tokens \"BRUSSELS\" and \"1996-08-22\" do not refer to any specific people. \"BRUSSELS\" is a location and \"1996-08-22\" is a date. Therefore, there are no tokens that can be extracted as referring to specific individuals.\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "[]\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "[\"The\", \"EU\", \"'s\", \"scientific\", \"veterinary\", \"and\", \"multidisciplinary\", \"committees\", \"are\", \"due\", \"to\", \"re-examine\", \"the\", \"issue\", \"early\", \"next\", \"month\", \"and\", \"make\", \"recommendations\", \"to\", \"the\", \"senior\", \"veterinary\", \"officials\", \".\"]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The tokens provided do not contain any specific names of individuals. The term \"EU\" refers to the European Union, which is an organization rather than a specific person. The rest of the tokens refer to committees and officials in a general sense without naming any identifiable individuals. Therefore, there are no extracted people from the given tokens.\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "[]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The tokens provided contain several references to specific individuals. \"Theon\" is mentioned multiple times, indicating it is a name of a person. Additionally, \"Eddard Stark\" is also referenced, which is another specific individual\\'s name. Both names are extracted as they refer to identifiable characters. The extraction includes each name as separate tokens.',\n",
       "    extracted_people=['Theon', 'Eddard', 'Stark']\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=68e87d0e5719427696e0ab99459318e9&amp;experiment_id=374362034103955121&amp;version=2.20.3\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=68e87d0e5719427696e0ab99459318e9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimized_people_extractor(tokens='The night was windless, the snow drifting straight down out of a cold black sky, yet the leaves of the heart tree were rustling his name. \"Theon,\" they seemed to whisper, \"Theon.\" The old gods, he thought. They know me. They know my name. I was Theon of House Greyjoy. I was a ward of Eddard Stark, a friend and brother to his children.'.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_extractor(tokens='The night was windless, the snow drifting straight down out of a cold black sky, yet the leaves of the heart tree were rustling his name. \"Theon,\" they seemed to whisper, \"Theon.\" The old gods, he thought. They know me. They know my name. I was Theon of House Greyjoy. I was a ward of Eddard Stark, a friend and brother to his children.'.split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
