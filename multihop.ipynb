{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/374362034103955121', creation_time=1741686562632, experiment_id='374362034103955121', last_update_time=1741686562632, lifecycle_stage='active', name='DSPy', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"DSPy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidand/dev/hello-dspy/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM('fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct', max_tokens=3000)\n",
    "gpt4o = dspy.LM('openai/gpt-4o', max_tokens=3000)\n",
    "\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U bm25s PyStemmer \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'wiki.abstracts.2017.tar.gz'...\n",
      "x wiki.abstracts.2017.jsonl\n"
     ]
    }
   ],
   "source": [
    "from dspy.utils import download\n",
    "\n",
    "download(\"https://huggingface.co/dspy/cache/resolve/main/wiki.abstracts.2017.tar.gz\")\n",
    "!tar -xzvf wiki.abstracts.2017.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5233330"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ujson\n",
    "corpus = []\n",
    "\n",
    "with open(\"wiki.abstracts.2017.jsonl\") as f:\n",
    "    for line in f:\n",
    "        line = ujson.loads(line)\n",
    "        corpus.append(f\"{line['title']} | {' '.join(line['text'])}\")\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    }
   ],
   "source": [
    "import bm25s\n",
    "import Stemmer\n",
    "\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
    "\n",
    "retriever = bm25s.BM25(k1=0.9, b=0.4)\n",
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
    "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
    "\n",
    "hpqa_ids = set()\n",
    "hover = [\n",
    "    dspy.Example(claim=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"claim\")\n",
    "    for x in hover\n",
    "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(hover)\n",
    "trainset, devset, testset = hover[:200], hover[200:500], hover[650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim: This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".\n",
      "Pages that must be retrieved: ['Chris Noonan', 'Academy Award for Best Director', 'Miss Potter']\n"
     ]
    }
   ],
   "source": [
    "example = trainset[0]\n",
    "\n",
    "print(\"Claim:\", example.claim)\n",
    "print(\"Pages that must be retrieved:\", example.titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, k: int) -> list[str]:\n",
    "    tokens = bm25s.tokenize(query, stopwords=\"en\", stemmer=stemmer, show_progress=False)\n",
    "    results, scores = retriever.retrieve(tokens, k=k, n_threads=1, show_progress=False)\n",
    "    run = {corpus[doc]: float(score) for doc, score in zip(results[0], scores[0])}\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hop(dspy.Module):\n",
    "    def __init__(self, num_docs=10, num_hops=4):\n",
    "        self.num_docs, self.num_hops = num_docs, num_hops\n",
    "        self.generate_query = dspy.ChainOfThought('claim, notes -> query')\n",
    "        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')\n",
    "\n",
    "    def forward(self, claim: str) -> list[str]:\n",
    "        notes = []\n",
    "        titles = []\n",
    "\n",
    "        for _ in range(self.num_hops):\n",
    "            query = self.generate_query(claim=claim, notes=notes).query\n",
    "            context = search(query, k=self.num_docs)\n",
    "            prediction = self.append_notes(claim=claim, notes=notes, context=context)\n",
    "            notes.extend(prediction.new_notes)\n",
    "            titles.extend(prediction.titles)\n",
    "        \n",
    "        return dspy.Prediction(notes=notes, titles=list(set(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_recall(example, pred, trace=None):\n",
    "    gold_titles = example.titles\n",
    "    recall = sum(x in pred.titles[:5] for x in gold_titles) / len(gold_titles)\n",
    "\n",
    "    # If we're \"bootstrapping\" for optimization, return True if and only if the recall is perfect.\n",
    "    if trace is not None:\n",
    "        return recall >= 1.0\n",
    "    \n",
    "    # If we're just doing inference, just measure the recall.\n",
    "    return recall\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=devset, metric=top5_recall, num_threads=16, display_progress=True, display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "evaluate(Hop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
