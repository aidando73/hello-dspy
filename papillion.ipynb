{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy-ai==2.5.41\n",
      "  Downloading dspy_ai-2.5.41-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting huggingface\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting sglang[all]\n",
      "  Downloading sglang-0.4.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting dspy>=2.5.3 (from dspy-ai==2.5.41)\n",
      "  Downloading dspy-2.6.12-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from sglang[all])\n",
      "  Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting requests (from sglang[all])\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from sglang[all])\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy (from sglang[all])\n",
      "  Downloading numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: IPython in ./env/lib/python3.10/site-packages (from sglang[all]) (8.34.0)\n",
      "Collecting setproctitle (from sglang[all])\n",
      "  Downloading setproctitle-1.3.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting backoff (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting joblib~=1.3 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openai (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting regex (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting ujson (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting optuna (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pydantic~=2.0 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting magicattr~=0.1.6 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting litellm<2.0.0,>=1.59.8 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading litellm-1.63.8-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting diskcache (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting json-repair (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading json_repair-0.39.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tenacity>=8.2.3 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting asyncer==0.0.8 (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting cachetools (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting cloudpickle (from dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->sglang[all])\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->sglang[all])\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->sglang[all])\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->sglang[all])\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->sglang[all])\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->sglang[all])\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->sglang[all])\n",
      "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->sglang[all])\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->sglang[all])\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->sglang[all])\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->sglang[all])\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->sglang[all])\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./env/lib/python3.10/site-packages (from IPython->sglang[all]) (5.14.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting anthropic>=0.20.0 (from sglang[all])\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken (from sglang[all])\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting sgl-kernel==0.0.5 (from sglang[all])\n",
      "  Downloading sgl_kernel-0.0.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting flashinfer_python==0.2.3 (from sglang[all])\n",
      "  Downloading flashinfer_python-0.2.3.tar.gz (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.5.1 (from sglang[all])\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting vllm<=0.7.2,>=0.6.4.post1 (from sglang[all])\n",
      "  Downloading vllm-0.7.2-cp38-abi3-manylinux1_x86_64.whl.metadata (12 kB)\n",
      "Collecting cuda-python (from sglang[all])\n",
      "  Downloading cuda_python-12.8.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting outlines<=0.1.11,>=0.0.44 (from sglang[all])\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting ninja (from flashinfer_python==0.2.3->sglang[all])\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting networkx (from torch==2.5.1->sglang[all])\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.5.1->sglang[all])\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->sglang[all])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1->sglang[all])\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1->sglang[all])\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1->sglang[all])\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from anthropic>=0.20.0->sglang[all])\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./env/lib/python3.10/site-packages (from jedi>=0.16->IPython->sglang[all]) (0.8.4)\n",
      "Collecting click (from litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting tokenizers (from litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting interegular (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting lark (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nest_asyncio in ./env/lib/python3.10/site-packages (from outlines<=0.1.11,>=0.0.44->sglang[all]) (1.6.0)\n",
      "Collecting referencing (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pycountry (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines<=0.1.11,>=0.0.44->sglang[all])\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.10/site-packages (from pexpect>4.3->IPython->sglang[all]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->sglang[all]) (0.2.13)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic~=2.0->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic~=2.0->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: psutil in ./env/lib/python3.10/site-packages (from vllm<=0.7.2,>=0.6.4.post1->sglang[all]) (5.9.1)\n",
      "Collecting sentencepiece (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting numpy (from sglang[all])\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting blake3 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting py-cpuinfo (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.48.2 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting protobuf (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn[standard] (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pillow (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting xgrammar>=0.1.6 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading xgrammar-0.1.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting partial-json-parser (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq in ./env/lib/python3.10/site-packages (from vllm<=0.7.2,>=0.6.4.post1->sglang[all]) (26.2.0)\n",
      "Collecting msgspec (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.10.0 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting einops (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.9.1 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting depyf==0.18.0 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting ray>=2.9 (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading ray-2.43.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting nvidia-ml-py>=12.560.30 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting torchaudio==2.5.1 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torchvision==0.20.1 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.28.post3 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting cuda-bindings~=12.8.0 (from cuda-python->sglang[all])\n",
      "  Downloading cuda_bindings-12.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading sqlalchemy-2.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting decord (from sglang[all])\n",
      "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Collecting hf_transfer (from sglang[all])\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting llguidance>=0.6.15 (from sglang[all])\n",
      "  Downloading llguidance-0.7.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting modelscope (from sglang[all])\n",
      "  Downloading modelscope-1.23.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting orjson (from sglang[all])\n",
      "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting python-multipart (from sglang[all])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting torchao>=0.7.0 (from sglang[all])\n",
      "  Downloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
      "Collecting transformers>=4.48.2 (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting uvloop (from sglang[all])\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.48.2->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.10/site-packages (from stack_data->IPython->sglang[all]) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.10/site-packages (from stack_data->IPython->sglang[all]) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in ./env/lib/python3.10/site-packages (from stack_data->IPython->sglang[all]) (0.2.3)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic>=0.20.0->sglang[all])\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic>=0.20.0->sglang[all])\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1->sglang[all])\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.59.8->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading rpds_py-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting opencv-python-headless>=4.0.0 (from mistral_common[opencv]>=1.5.0->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting aiohttp_cors (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting opencensus (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting smart_open (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading virtualenv-20.29.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna->dspy>=2.5.3->dspy-ai==2.5.41)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in ./env/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all]) (4.3.6)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt (from smart_open->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting protobuf (from vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm<=0.7.2,>=0.6.4.post1->sglang[all])\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading dspy_ai-2.5.41-py3-none-any.whl (339 kB)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading dspy-2.6.12-py3-none-any.whl (258 kB)\n",
      "Downloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m185.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m232.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading sglang-0.4.4-py3-none-any.whl (986 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.5/986.5 kB\u001b[0m \u001b[31m134.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sgl_kernel-0.0.5-cp39-abi3-manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m149.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m171.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m223.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m188.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m194.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m201.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m202.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m214.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m189.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m214.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading litellm-1.63.8-py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m244.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m147.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m284.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m191.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading vllm-0.7.2-cp38-abi3-manylinux1_x86_64.whl (264.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m184.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m229.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m233.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m198.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m166.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cuda_python-12.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading json_repair-0.39.1-py3-none-any.whl (20 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m223.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cuda_bindings-12.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading llguidance-0.7.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m226.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m218.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
      "Downloading ray-2.43.0-cp310-cp310-manylinux2014_x86_64.whl (67.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 MB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading sqlalchemy-2.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m223.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m232.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m229.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading modelscope-1.23.2-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m262.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m229.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m237.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m199.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m204.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m266.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading virtualenv-20.29.3-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m220.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: flashinfer_python\n",
      "  Building wheel for flashinfer_python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashinfer_python: filename=flashinfer_python-0.2.3-py3-none-any.whl size=3297233 sha256=142678ccca4fefe4fbc8a4de3ef5f63b61698a2910d139a8618ad33502c12cdf\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/17/53/c2b53ba3810ce9b53f47d7737c63a6a0894432b696e2aa8400\n",
      "Successfully built flashinfer_python\n",
      "Installing collected packages: torchao, sentencepiece, pytz, py-spy, py-cpuinfo, opencensus-context, nvidia-ml-py, mpmath, magicattr, huggingface, distlib, cuda-bindings, colorful, blake3, zipp, xxhash, wrapt, websockets, uvloop, urllib3, ujson, tzdata, tqdm, tenacity, sympy, sniffio, sgl-kernel, setproctitle, safetensors, rpds-py, regex, pyyaml, python-multipart, python-dotenv, pydantic-core, pycountry, pyasn1, pyarrow, protobuf, propcache, prometheus_client, pillow, partial-json-parser, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, multidict, msgspec, msgpack, MarkupSafe, llguidance, lark, json-repair, joblib, jiter, interegular, idna, httptools, hf_transfer, h11, grpcio, greenlet, fsspec, frozenlist, filelock, einops, distro, diskcache, dill, cuda-python, colorlog, cloudpickle, click, charset-normalizer, certifi, cachetools, backoff, attrs, async-timeout, astor, annotated-types, airportsdata, aiohappyeyeballs, yarl, virtualenv, uvicorn, triton, sqlalchemy, smart_open, rsa, requests, referencing, pydantic, pyasn1-modules, proto-plus, pandas, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, Mako, jinja2, importlib-metadata, httpcore, googleapis-common-protos, gguf, depyf, decord, anyio, aiosignal, watchfiles, tiktoken, starlette, nvidia-cusolver-cu12, modelscope, lm-format-enforcer, jsonschema-specifications, huggingface-hub, httpx, google-auth, asyncer, alembic, aiohttp, torch, tokenizers, sglang, prometheus-fastapi-instrumentator, optuna, openai, jsonschema, google-api-core, fastapi, anthropic, aiohttp_cors, xformers, transformers, torchvision, torchaudio, ray, outlines_core, opencensus, mistral_common, litellm, flashinfer_python, datasets, xgrammar, outlines, dspy, compressed-tensors, vllm, dspy-ai\n",
      "Successfully installed Mako-1.3.9 MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiohttp_cors-0.7.0 aiosignal-1.3.2 airportsdata-20250224 alembic-1.15.1 annotated-types-0.7.0 anthropic-0.49.0 anyio-4.8.0 astor-0.8.1 async-timeout-5.0.1 asyncer-0.0.8 attrs-25.3.0 backoff-2.2.1 blake3-1.0.4 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 colorlog-6.9.0 compressed-tensors-0.9.1 cuda-bindings-12.8.0 cuda-python-12.8.0 datasets-3.3.2 decord-0.6.0 depyf-0.18.0 dill-0.3.8 diskcache-5.6.3 distlib-0.3.9 distro-1.9.0 dspy-2.6.12 dspy-ai-2.5.41 einops-0.8.1 fastapi-0.115.11 filelock-3.17.0 flashinfer_python-0.2.3 frozenlist-1.5.0 fsspec-2024.12.0 gguf-0.10.0 google-api-core-2.24.2 google-auth-2.38.0 googleapis-common-protos-1.69.1 greenlet-3.1.1 grpcio-1.71.0 h11-0.14.0 hf_transfer-0.1.9 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 huggingface-0.0.1 huggingface-hub-0.29.3 idna-3.10 importlib-metadata-8.6.1 interegular-0.3.3 jinja2-3.1.6 jiter-0.9.0 joblib-1.4.2 json-repair-0.39.1 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lark-1.2.2 litellm-1.63.8 llguidance-0.7.0 lm-format-enforcer-0.10.11 magicattr-0.1.6 mistral_common-1.5.3 modelscope-1.23.2 mpmath-1.3.0 msgpack-1.1.0 msgspec-0.19.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 ninja-1.11.1.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py-12.570.86 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-1.66.3 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-headless-4.11.0.86 optuna-4.2.1 orjson-3.10.15 outlines-0.1.11 outlines_core-0.1.26 pandas-2.2.3 partial-json-parser-0.2.1.1.post5 pillow-11.1.0 prometheus-fastapi-instrumentator-7.0.2 prometheus_client-0.21.1 propcache-0.3.0 proto-plus-1.26.1 protobuf-5.29.3 py-cpuinfo-9.0.0 py-spy-0.4.0 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycountry-24.6.1 pydantic-2.10.6 pydantic-core-2.27.2 python-dotenv-1.0.1 python-multipart-0.0.20 pytz-2025.1 pyyaml-6.0.2 ray-2.43.0 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 rpds-py-0.23.1 rsa-4.9 safetensors-0.5.3 sentencepiece-0.2.0 setproctitle-1.3.5 sgl-kernel-0.0.5 sglang-0.4.4 smart_open-7.1.0 sniffio-1.3.1 sqlalchemy-2.0.39 starlette-0.46.1 sympy-1.13.1 tenacity-9.0.0 tiktoken-0.9.0 tokenizers-0.21.1 torch-2.5.1 torchao-0.9.0 torchaudio-2.5.1 torchvision-0.20.1 tqdm-4.67.1 transformers-4.48.3 triton-3.1.0 tzdata-2025.1 ujson-5.10.0 urllib3-2.3.0 uvicorn-0.34.0 uvloop-0.21.0 virtualenv-20.29.3 vllm-0.7.2 watchfiles-1.0.4 websockets-15.0.1 wrapt-1.17.2 xformers-0.0.28.post3 xgrammar-0.1.15 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dspy-ai==2.5.41 sglang[all] datasets huggingface python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://flashinfer.ai/whl/cu121/torch2.4/\n",
      "Collecting flashinfer\n",
      "  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.0.post1/flashinfer-0.2.0.post1%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl (405.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.8/405.8 MB\u001b[0m \u001b[31m152.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of flashinfer to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.0/flashinfer-0.2.0%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl (405.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.8/405.8 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.1.6/flashinfer-0.1.6%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl (1322.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 GB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flashinfer\n",
      "Successfully installed flashinfer-0.1.6+cu121torch2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/ --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT_NUMBER = 7501 # You can change the port number here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command to start the server\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0 python -m sglang.launch_server --port 7501 --model-path meta-llama/Llama-3.1-8B-Instruct\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/hello-dspy/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "local_lm = dspy.LM('openai/sglang/Llama-3.1-8B-Instruct', api_base=f\"http://127.0.0.1:{PORT_NUMBER}/v1\", api_key=\"\", max_tokens=4000)\n",
    "dspy.configure(lm=local_lm)\n",
    "\n",
    "openai_lm = dspy.LM(model=\"openai/gpt-4o-mini\", max_tokens=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class CreateOnePrompt(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that is very mindful of user privacy. You have access to a powerful large language model that you can query. Given a user request, create a prompt for your large language model that preserves user privacy, so that this model can help you complete the user request. Provide the prompt directly without any preamble. DO NOT COMPLETE THE USER QUERY, ONLY GENERATE A PROMPT.\n",
    "    \"\"\"\n",
    "    userQuery = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    createdPrompt = dspy.OutputField()\n",
    "\n",
    "class InfoAggregator(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a helpful assistant. Respond to queries from the user.\n",
    "    \"\"\"\n",
    "\n",
    "    userQuery = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    modelExampleResponses = dspy.InputField(desc=\"Information from a more powerful language model responding to related queries. Complete the user query by referencing this information. Only you have access to this information.\")\n",
    "    finalOutput = dspy.OutputField()\n",
    "\n",
    "class PAPILLON(dspy.Module):\n",
    "    def __init__(self, untrusted_model):\n",
    "        self.prompt_creater = dspy.ChainOfThought(CreateOnePrompt)\n",
    "        self.info_aggregator = dspy.Predict(InfoAggregator)\n",
    "        self.untrusted_model = untrusted_model\n",
    "\n",
    "    def forward(self, user_query):\n",
    "        try:\n",
    "            prompt = self.prompt_creater(userQuery=user_query).createdPrompt\n",
    "            response = self.untrusted_model(prompt)[0]\n",
    "            output = self.info_aggregator(userQuery=user_query, modelExampleResponses=response)\n",
    "        except Exception:\n",
    "            return dspy.Prediction(prompt=\"\", output=\"\", gptResponse=\"\")\n",
    "\n",
    "        return dspy.Prediction(prompt=prompt, output=output.finalOutput, gptResponse=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 237/237 [00:00<00:00, 8149.49 examples/s]\n",
      "Generating train split: 100%|██████████| 664/664 [00:00<00:00, 12710.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "pupa_tnb = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_tnb\")\n",
    "pupa_new = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_hash</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>user_query</th>\n",
       "      <th>target_response</th>\n",
       "      <th>pii_units</th>\n",
       "      <th>redacted_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e7a39c9e8d82872ca048996ee756350e</td>\n",
       "      <td>job, visa, and other applications</td>\n",
       "      <td>Rachel Zheng is a clerk in the Administrative ...</td>\n",
       "      <td>Rachel Zheng 是 H&amp;R Technology 行政部门的职员。当她回到办公室时...</td>\n",
       "      <td>rachel||johnny||univeristy of westminster||wes...</td>\n",
       "      <td>[REDACTED] is a clerk in the Administrative De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ef034853452a12782a0aca4e71c9d62</td>\n",
       "      <td>job, visa, and other applications</td>\n",
       "      <td>Please describe the job knowledge requirements...</td>\n",
       "      <td>The International Advising Assistant position ...</td>\n",
       "      <td>university</td>\n",
       "      <td>Please describe the job knowledge requirements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9d10fe1f5b6657a7a5ccc0180a5938c8</td>\n",
       "      <td>job, visa, and other applications</td>\n",
       "      <td>i want to write a letter to the royal college ...</td>\n",
       "      <td>[Your Name] [Your Address] [City, State, ZIP C...</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>i want to write a letter to the royal college ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  conversation_hash                 predicted_category  \\\n",
       "0  e7a39c9e8d82872ca048996ee756350e  job, visa, and other applications   \n",
       "1  5ef034853452a12782a0aca4e71c9d62  job, visa, and other applications   \n",
       "2  9d10fe1f5b6657a7a5ccc0180a5938c8  job, visa, and other applications   \n",
       "\n",
       "                                          user_query  \\\n",
       "0  Rachel Zheng is a clerk in the Administrative ...   \n",
       "1  Please describe the job knowledge requirements...   \n",
       "2  i want to write a letter to the royal college ...   \n",
       "\n",
       "                                     target_response  \\\n",
       "0  Rachel Zheng 是 H&R Technology 行政部门的职员。当她回到办公室时...   \n",
       "1  The International Advising Assistant position ...   \n",
       "2  [Your Name] [Your Address] [City, State, ZIP C...   \n",
       "\n",
       "                                           pii_units  \\\n",
       "0  rachel||johnny||univeristy of westminster||wes...   \n",
       "1                                         university   \n",
       "2                                              Sudan   \n",
       "\n",
       "                                      redacted_query  \n",
       "0  [REDACTED] is a clerk in the Administrative De...  \n",
       "1  Please describe the job knowledge requirements...  \n",
       "2  i want to write a letter to the royal college ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Zheng is a clerk in the Administrative Department of H&R Technology. When she returns to the office, she finds a telephone message left by Johnny Bay, a manager of her department. In five days, Johnny will fly with the vice-president to the Univeristy of Westminster in order to attend a meeting. Johnny asks Rachel to book a hotel for them in Westminster. She needs to write an email to Johnny to explain her suggestions before booking. 请将以上句子翻译成中文\n",
      "rachel||johnny||univeristy of westminster||westminster||johnny bay||rachel zheng||h&r technology\n",
      "[REDACTED] is a clerk in the Administrative Department of [REDACTED]. When she returns to the office, she finds a telephone message left by [REDACTED], a manager of her department. In five days, [REDACTED] will fly with the vice-president to the [REDACTED] in order to attend a meeting. [REDACTED] asks [REDACTED] to book a hotel for them in [REDACTED]. She needs to write an email to [REDACTED] to explain her suggestions before booking. 请将以上句子翻译成中文\n"
     ]
    }
   ],
   "source": [
    "# Let's first take a look at some data examples\n",
    "from IPython.display import display\n",
    "display(pupa_tnb[\"train\"].to_pandas().head(3))\n",
    "print(pupa_tnb[\"train\"][\"user_query\"][0])\n",
    "print(pupa_tnb[\"train\"][\"pii_units\"][0])\n",
    "print(pupa_tnb[\"train\"][\"redacted_query\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 training examples, 150 dev examples, and 364 test examples.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    dspy.Example({\n",
    "        \"target_response\": x[\"target_response\"],\n",
    "        \"user_query\": x[\"user_query\"],\n",
    "        \"pii_str\": x[\"pii_units\"]\n",
    "    }).with_inputs(\"user_query\")\n",
    "    for x in pupa_new[\"train\"]\n",
    "]\n",
    "\n",
    "trainset, devset, testset = examples[:150], examples[150:300], examples[300:]\n",
    "print(f\"Loaded {len(trainset)} training examples, {len(devset)} dev examples, and {len(testset)} test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeQuality(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are comparing the quality of two responses, given a user query.\n",
    "    Is response A at least as good as response B?\n",
    "    \"\"\"\n",
    "\n",
    "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    response_A = dspy.InputField()\n",
    "    response_B = dspy.InputField()\n",
    "    judgment: bool = dspy.OutputField()\n",
    "\n",
    "class JudgeLeakage(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Count the number information pieces in `pii` that are simultaneously (i) forms of PII and (ii) are leaked into the prompt given.\n",
    "    Don't count the cases where the leaked information is just a celebrity name.\n",
    "    Don't count the cases where the `pii` information does not appear in the prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    pii = dspy.InputField()\n",
    "    prompt = dspy.InputField()\n",
    "    num_pii_leaked: int = dspy.OutputField()\n",
    "\n",
    "class LLMJudge(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
    "        self.fact_checker = dspy.ChainOfThought(JudgeLeakage)\n",
    "\n",
    "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
    "        judgment_1 = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp).judgment\n",
    "        judgment_2 = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp).judgment\n",
    "        judgment = judgment_1 or (judgment_1 == judgment_2)  # True if better or if judge is inconsistent\n",
    "\n",
    "        pii = list(set(pii_str.split(\"||\"))) # The pii_str field must be separated by `||`\n",
    "        pii_score = self.fact_checker(pii=pii, prompt=updated_query).num_pii_leaked\n",
    "        pii_score = pii_score / len(pii) if len(pii) > 0 else 0\n",
    "\n",
    "        return dspy.Prediction(quality=judgment, leakage=pii_score)\n",
    "\n",
    "dspy.configure(experimental=True)\n",
    "llm_judge = LLMJudge()\n",
    "llm_judge.set_lm(openai_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(gold, pred, trace=None):\n",
    "    return llm_judge(\n",
    "        user_query=gold.user_query,\n",
    "        new_resp=pred.output,\n",
    "        og_resp=gold.target_response,\n",
    "        updated_query=pred.prompt,\n",
    "        pii_str=gold.pii_str,\n",
    "    )\n",
    "\n",
    "def compute_quality(gold, pred, trace=None):\n",
    "    return compute_metrics(gold, pred, trace).quality\n",
    "\n",
    "def compute_leakage(gold, pred, trace=None):\n",
    "    return compute_metrics(gold, pred, trace).leakage\n",
    "\n",
    "def compute_overall_score(gold, pred, trace=None):\n",
    "    metrics = compute_metrics(gold, pred, trace)\n",
    "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
    "    return overall_score >= 1.0 if trace is not None else overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot = PAPILLON(untrusted_model=openai_lm)\n",
    "\n",
    "kwargs = dict(num_threads=16, display_progress=True, display_table=5, max_errors=100)\n",
    "evaluate = dspy.Evaluate(metric=compute_overall_score, devset=devset, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 119.00 / 150 (79.3%): 100%|██████████| 150/150 [05:03<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 00:00:42 INFO dspy.evaluate.evaluate: Average Metric: 119 / 150 (79.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>gptResponse</th>\n",
       "      <th>compute_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6. training 7. would be 8. the climb 9. caught 10. all 11. congrat...</td>\n",
       "      <td>It had always been my dream to climb Mount Everest, and last year ...</td>\n",
       "      <td>nepal||ama dablam||dingboche</td>\n",
       "      <td>Please generate a text about a person's experience climbing a high...</td>\n",
       "      <td>It had always been my dream to climb Mount Everest, and last year ...</td>\n",
       "      <td>As I stood at the base of the towering peak, a sense of both excit...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sorry, but I am an AI language model and do not have access to...</td>\n",
       "      <td>Tell me about Elaine Paul</td>\n",
       "      <td>||elaine</td>\n",
       "      <td>Please provide a brief biography of a notable computer scientist w...</td>\n",
       "      <td>I couldn't find any information on a notable computer scientist na...</td>\n",
       "      <td>One notable computer scientist whose name starts with \"E\" and \"P\" ...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ChatGPT) There are various fan translations available online that...</td>\n",
       "      <td>Leo must use the language that ChatGPT wouldn’t use. Additionally,...</td>\n",
       "      <td>open ai, chatgpt, or any party affiliated with them</td>\n",
       "      <td>Please generate a response to the following question: \"How to lega...</td>\n",
       "      <td>(Leo) Ah, the thrill of playing MOTHER 3 outside Japan without kno...</td>\n",
       "      <td>**ChatGPT's Response:** To legally play a game outside its origina...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Focus Report: Iden's Sleep and Classroom Engagement Date: [Current...</td>\n",
       "      <td>Write a focus report for Iden, he is a three year old student who ...</td>\n",
       "      <td>iden</td>\n",
       "      <td>Please generate a focus report for a three-year-old student who ex...</td>\n",
       "      <td>**Focus Report for Iden** **Date:** [Insert Date] **Age:** 3 Years...</td>\n",
       "      <td>**Focus Report for [Student's Name]** **Date:** [Insert Date] **Ag...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### 3. Findings and Reflection #### Implementation Discussion Our ...</td>\n",
       "      <td>For the following question: “Each team will have 2/3 members and 1...</td>\n",
       "      <td>https://journals.sagepub.com/doi/full/10.1177/2055668319862151</td>\n",
       "      <td>Please write an entry for the '3. Findings and Reflection' section...</td>\n",
       "      <td>### 3. Findings and Reflection The development of our robotic syst...</td>\n",
       "      <td>### 3. Findings and Reflection The development of our robotic syst...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  6. training 7. would be 8. the climb 9. caught 10. all 11. congrat...   \n",
       "1  I'm sorry, but I am an AI language model and do not have access to...   \n",
       "2  (ChatGPT) There are various fan translations available online that...   \n",
       "3  Focus Report: Iden's Sleep and Classroom Engagement Date: [Current...   \n",
       "4  ### 3. Findings and Reflection #### Implementation Discussion Our ...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  It had always been my dream to climb Mount Everest, and last year ...   \n",
       "1                                              Tell me about Elaine Paul   \n",
       "2  Leo must use the language that ChatGPT wouldn’t use. Additionally,...   \n",
       "3  Write a focus report for Iden, he is a three year old student who ...   \n",
       "4  For the following question: “Each team will have 2/3 members and 1...   \n",
       "\n",
       "                                                          pii_str  \\\n",
       "0                                    nepal||ama dablam||dingboche   \n",
       "1                                                        ||elaine   \n",
       "2             open ai, chatgpt, or any party affiliated with them   \n",
       "3                                                            iden   \n",
       "4  https://journals.sagepub.com/doi/full/10.1177/2055668319862151   \n",
       "\n",
       "                                                                  prompt  \\\n",
       "0  Please generate a text about a person's experience climbing a high...   \n",
       "1  Please provide a brief biography of a notable computer scientist w...   \n",
       "2  Please generate a response to the following question: \"How to lega...   \n",
       "3  Please generate a focus report for a three-year-old student who ex...   \n",
       "4  Please write an entry for the '3. Findings and Reflection' section...   \n",
       "\n",
       "                                                                  output  \\\n",
       "0  It had always been my dream to climb Mount Everest, and last year ...   \n",
       "1  I couldn't find any information on a notable computer scientist na...   \n",
       "2  (Leo) Ah, the thrill of playing MOTHER 3 outside Japan without kno...   \n",
       "3  **Focus Report for Iden** **Date:** [Insert Date] **Age:** 3 Years...   \n",
       "4  ### 3. Findings and Reflection The development of our robotic syst...   \n",
       "\n",
       "                                                             gptResponse  \\\n",
       "0  As I stood at the base of the towering peak, a sense of both excit...   \n",
       "1  One notable computer scientist whose name starts with \"E\" and \"P\" ...   \n",
       "2  **ChatGPT's Response:** To legally play a game outside its origina...   \n",
       "3  **Focus Report for [Student's Name]** **Date:** [Insert Date] **Ag...   \n",
       "4  ### 3. Findings and Reflection The development of our robotic syst...   \n",
       "\n",
       "  compute_quality  \n",
       "0       ✔️ [True]  \n",
       "1       ✔️ [True]  \n",
       "2       ✔️ [True]  \n",
       "3       ✔️ [True]  \n",
       "4       ✔️ [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 145 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "79.33"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's evaluate response quality!\n",
    "evaluate(zeroshot, metric=compute_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 42.24 / 150 (28.2%): 100%|██████████| 150/150 [00:00<00:00, 1788.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 00:01:14 INFO dspy.evaluate.evaluate: Average Metric: 42.24035353535353 / 150 (28.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>gptResponse</th>\n",
       "      <th>compute_leakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6. training 7. would be 8. the climb 9. caught 10. all 11. congrat...</td>\n",
       "      <td>It had always been my dream to climb Mount Everest, and last year ...</td>\n",
       "      <td>nepal||ama dablam||dingboche</td>\n",
       "      <td>Please generate a text about a person's experience climbing a high...</td>\n",
       "      <td>It had always been my dream to climb Mount Everest, and last year ...</td>\n",
       "      <td>As I stood at the base of the towering peak, a sense of both excit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sorry, but I am an AI language model and do not have access to...</td>\n",
       "      <td>Tell me about Elaine Paul</td>\n",
       "      <td>||elaine</td>\n",
       "      <td>Please provide a brief biography of a notable computer scientist w...</td>\n",
       "      <td>I couldn't find any information on a notable computer scientist na...</td>\n",
       "      <td>One notable computer scientist whose name starts with \"E\" and \"P\" ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ChatGPT) There are various fan translations available online that...</td>\n",
       "      <td>Leo must use the language that ChatGPT wouldn’t use. Additionally,...</td>\n",
       "      <td>open ai, chatgpt, or any party affiliated with them</td>\n",
       "      <td>Please generate a response to the following question: \"How to lega...</td>\n",
       "      <td>(Leo) Ah, the thrill of playing MOTHER 3 outside Japan without kno...</td>\n",
       "      <td>**ChatGPT's Response:** To legally play a game outside its origina...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Focus Report: Iden's Sleep and Classroom Engagement Date: [Current...</td>\n",
       "      <td>Write a focus report for Iden, he is a three year old student who ...</td>\n",
       "      <td>iden</td>\n",
       "      <td>Please generate a focus report for a three-year-old student who ex...</td>\n",
       "      <td>**Focus Report for Iden** **Date:** [Insert Date] **Age:** 3 Years...</td>\n",
       "      <td>**Focus Report for [Student's Name]** **Date:** [Insert Date] **Ag...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### 3. Findings and Reflection #### Implementation Discussion Our ...</td>\n",
       "      <td>For the following question: “Each team will have 2/3 members and 1...</td>\n",
       "      <td>https://journals.sagepub.com/doi/full/10.1177/2055668319862151</td>\n",
       "      <td>Please write an entry for the '3. Findings and Reflection' section...</td>\n",
       "      <td>### 3. Findings and Reflection The development of our robotic syst...</td>\n",
       "      <td>### 3. Findings and Reflection The development of our robotic syst...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  6. training 7. would be 8. the climb 9. caught 10. all 11. congrat...   \n",
       "1  I'm sorry, but I am an AI language model and do not have access to...   \n",
       "2  (ChatGPT) There are various fan translations available online that...   \n",
       "3  Focus Report: Iden's Sleep and Classroom Engagement Date: [Current...   \n",
       "4  ### 3. Findings and Reflection #### Implementation Discussion Our ...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  It had always been my dream to climb Mount Everest, and last year ...   \n",
       "1                                              Tell me about Elaine Paul   \n",
       "2  Leo must use the language that ChatGPT wouldn’t use. Additionally,...   \n",
       "3  Write a focus report for Iden, he is a three year old student who ...   \n",
       "4  For the following question: “Each team will have 2/3 members and 1...   \n",
       "\n",
       "                                                          pii_str  \\\n",
       "0                                    nepal||ama dablam||dingboche   \n",
       "1                                                        ||elaine   \n",
       "2             open ai, chatgpt, or any party affiliated with them   \n",
       "3                                                            iden   \n",
       "4  https://journals.sagepub.com/doi/full/10.1177/2055668319862151   \n",
       "\n",
       "                                                                  prompt  \\\n",
       "0  Please generate a text about a person's experience climbing a high...   \n",
       "1  Please provide a brief biography of a notable computer scientist w...   \n",
       "2  Please generate a response to the following question: \"How to lega...   \n",
       "3  Please generate a focus report for a three-year-old student who ex...   \n",
       "4  Please write an entry for the '3. Findings and Reflection' section...   \n",
       "\n",
       "                                                                  output  \\\n",
       "0  It had always been my dream to climb Mount Everest, and last year ...   \n",
       "1  I couldn't find any information on a notable computer scientist na...   \n",
       "2  (Leo) Ah, the thrill of playing MOTHER 3 outside Japan without kno...   \n",
       "3  **Focus Report for Iden** **Date:** [Insert Date] **Age:** 3 Years...   \n",
       "4  ### 3. Findings and Reflection The development of our robotic syst...   \n",
       "\n",
       "                                                             gptResponse  \\\n",
       "0  As I stood at the base of the towering peak, a sense of both excit...   \n",
       "1  One notable computer scientist whose name starts with \"E\" and \"P\" ...   \n",
       "2  **ChatGPT's Response:** To legally play a game outside its origina...   \n",
       "3  **Focus Report for [Student's Name]** **Date:** [Insert Date] **Ag...   \n",
       "4  ### 3. Findings and Reflection The development of our robotic syst...   \n",
       "\n",
       "  compute_leakage  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 145 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28.16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's evaluate PII leakage!\n",
    "evaluate(zeroshot, metric=compute_leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example user_query from devset:\n",
      "From the list of following programs: BIDA from CMU, Machine Learning from Columbia University, Data Science from JHU, AI from JHU, and MBA from JHU, which are the best compliment programs if I want to study for 2 Masters programs and to become a technical leader at the Boeing Company?\n"
     ]
    }
   ],
   "source": [
    "# Let's print an example user_query from the devset\n",
    "print(\"\\nExample user_query from devset:\")\n",
    "if len(devset) > 0:\n",
    "    example = devset[8]\n",
    "    print(example.user_query)\n",
    "else:\n",
    "    print(\"No examples available in the devset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    prompt=\"Please suggest two Master's programs that are highly complementary and can help an individual become a technical leader in the aerospace industry. The programs should be from top universities and have a strong reputation in the field. Consider factors such as curriculum, research opportunities, industry connections, and alumni network.\\n\\nAssume the individual has a strong background in a technical field and is looking to advance their career in a leadership role at Boeing Company or a similar organization.\",\n",
      "    output=\"Based on your goal of becoming a technical leader at the Boeing Company, I recommend the following two Master's programs as the best complements:\\n\\n1. **Master of Science in Data Science from JHU**: This program will provide you with a strong foundation in data analysis, machine learning, and statistical modeling, which are essential skills for making data-driven decisions in the aerospace industry.\\n2. **Master of Science in AI from JHU**: This program will equip you with advanced knowledge in artificial intelligence, including machine learning, deep learning, and natural language processing, which are critical for developing intelligent systems and making informed decisions in the aerospace sector.\\n\\nThese two programs will provide you with a robust foundation in both technical expertise and leadership skills, making you a strong candidate for a technical leadership role at Boeing or similar organizations.\",\n",
      "    gptResponse=\"To become a technical leader in the aerospace industry, pursuing two complementary Master's programs can provide a robust foundation in both technical expertise and leadership skills. Here are two highly regarded programs from top universities that align well with your goals:\\n\\n### 1. Master of Science in Aerospace Engineering\\n**University:** Massachusetts Institute of Technology (MIT)  \\n**Program Overview:**  \\nMIT's Department of Aeronautics and Astronautics offers a Master of Science in Aerospace Engineering that is renowned for its rigorous curriculum and cutting-edge research opportunities. The program covers advanced topics in aerodynamics, propulsion, structures, and systems engineering, providing a strong technical foundation. Students can engage in research projects that often collaborate with industry leaders, including Boeing.\\n\\n**Key Features:**\\n- **Curriculum:** Focuses on advanced aerospace topics, systems engineering, and hands-on projects.\\n- **Research Opportunities:** Access to state-of-the-art labs and facilities, with opportunities to work on projects related to space exploration, aircraft design, and more.\\n- **Industry Connections:** Strong ties with leading aerospace companies, including Boeing, Lockheed Martin, and NASA.\\n- **Alumni Network:** A vast and influential alumni network in the aerospace sector, providing valuable connections for career advancement.\\n\\n### 2. Master of Business Administration (MBA) with a focus on Technology Management\\n**University:** Stanford University  \\n**Program Overview:**  \\nStanford's Graduate School of Business offers an MBA program that emphasizes innovation and technology management. This program is ideal for technical professionals looking to transition into leadership roles. The curriculum includes courses on strategic management, entrepreneurship, and operations, which are essential for leading technical teams in the aerospace industry.\\n\\n**Key Features:**\\n- **Curriculum:** Offers courses in leadership, strategy, and technology management, tailored for those in technical fields.\\n- **Research Opportunities:** Access to interdisciplinary projects and initiatives, including the Stanford Technology Ventures Program (STVP).\\n- **Industry Connections:** Strong connections with Silicon Valley and the aerospace industry, providing networking opportunities with leaders in the field.\\n- **Alumni Network:** A powerful alumni network that includes influential figures in technology and aerospace, facilitating mentorship and career opportunities.\\n\\n### Complementary Nature of the Programs\\n- **Technical and Leadership Balance:** The Aerospace Engineering program provides the technical depth needed for understanding complex aerospace systems, while the MBA focuses on leadership, management, and strategic thinking.\\n- **Interdisciplinary Collaboration:** Both programs encourage collaboration across disciplines, allowing you to apply technical knowledge in a business context, which is crucial for leadership roles.\\n- **Networking Opportunities:** Together, these programs offer extensive networking opportunities with industry leaders, enhancing your visibility and career prospects in the aerospace sector.\\n\\nBy pursuing these two Master's programs, you will be well-equipped to take on a technical leadership role at Boeing or similar organizations, combining deep technical knowledge with strong management and leadership skills.\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "user_query = \"\"\"\n",
    "From the list of following programs: BIDA from CMU, Machine Learning from Columbia University, Data Science from JHU, AI from JHU, and MBA from JHU, which are the best compliment programs if I want to study for 2 Masters programs and to become a technical leader at the Boeing Company?\n",
    "\"\"\"\n",
    "print(zeroshot(user_query=user_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-14T00:04:34.457078]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `userQuery` (str): The user's request to be fulfilled.\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `createdPrompt` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## userQuery ## ]]\n",
      "{userQuery}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## createdPrompt ## ]]\n",
      "{createdPrompt}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a helpful assistant that is very mindful of user privacy. You have access to a powerful large language model that you can query. Given a user request, create a prompt for your large language model that preserves user privacy, so that this model can help you complete the user request. Provide the prompt directly without any preamble. DO NOT COMPLETE THE USER QUERY, ONLY GENERATE A PROMPT.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## userQuery ## ]]\n",
      "\n",
      "From the list of following programs: BIDA from CMU, Machine Learning from Columbia University, Data Science from JHU, AI from JHU, and MBA from JHU, which are the best compliment programs if I want to study for 2 Masters programs and to become a technical leader at the Boeing Company?\n",
      "\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## createdPrompt ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To preserve user privacy, I will create a prompt that does not include the user's name or any identifying information. I will also ensure that the prompt is focused on the user's goals and requirements, rather than their personal characteristics.\n",
      "\n",
      "The user wants to study two Master's programs to become a technical leader at Boeing Company. This suggests that they are interested in a career in a technical field, possibly in aerospace or a related industry. They are looking for two programs that complement each other and will help them achieve their career goals.\n",
      "\n",
      "[[ ## createdPrompt ## ]]\n",
      "Please suggest two Master's programs that are highly complementary and can help an individual become a technical leader in the aerospace industry. The programs should be from top universities and have a strong reputation in the field. Consider factors such as curriculum, research opportunities, industry connections, and alumni network.\n",
      "\n",
      "Assume the individual has a strong background in a technical field and is looking to advance their career in a leadership role at Boeing Company or a similar organization.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-14T00:04:47.969496]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `userQuery` (str): The user's request to be fulfilled.\n",
      "2. `modelExampleResponses` (str): Information from a more powerful language model responding to related queries. Complete the user query by referencing this information. Only you have access to this information.\n",
      "\n",
      "Your output fields are:\n",
      "1. `finalOutput` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## userQuery ## ]]\n",
      "{userQuery}\n",
      "\n",
      "[[ ## modelExampleResponses ## ]]\n",
      "{modelExampleResponses}\n",
      "\n",
      "[[ ## finalOutput ## ]]\n",
      "{finalOutput}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a helpful assistant. Respond to queries from the user.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## userQuery ## ]]\n",
      "\n",
      "From the list of following programs: BIDA from CMU, Machine Learning from Columbia University, Data Science from JHU, AI from JHU, and MBA from JHU, which are the best compliment programs if I want to study for 2 Masters programs and to become a technical leader at the Boeing Company?\n",
      "\n",
      "\n",
      "[[ ## modelExampleResponses ## ]]\n",
      "To become a technical leader in the aerospace industry, pursuing two complementary Master's programs can provide a robust foundation in both technical expertise and leadership skills. Here are two highly regarded programs from top universities that align well with your goals:\n",
      "\n",
      "### 1. Master of Science in Aerospace Engineering\n",
      "**University:** Massachusetts Institute of Technology (MIT)  \n",
      "**Program Overview:**  \n",
      "MIT's Department of Aeronautics and Astronautics offers a Master of Science in Aerospace Engineering that is renowned for its rigorous curriculum and cutting-edge research opportunities. The program covers advanced topics in aerodynamics, propulsion, structures, and systems engineering, providing a strong technical foundation. Students can engage in research projects that often collaborate with industry leaders, including Boeing.\n",
      "\n",
      "**Key Features:**\n",
      "- **Curriculum:** Focuses on advanced aerospace topics, systems engineering, and hands-on projects.\n",
      "- **Research Opportunities:** Access to state-of-the-art labs and facilities, with opportunities to work on projects related to space exploration, aircraft design, and more.\n",
      "- **Industry Connections:** Strong ties with leading aerospace companies, including Boeing, Lockheed Martin, and NASA.\n",
      "- **Alumni Network:** A vast and influential alumni network in the aerospace sector, providing valuable connections for career advancement.\n",
      "\n",
      "### 2. Master of Business Administration (MBA) with a focus on Technology Management\n",
      "**University:** Stanford University  \n",
      "**Program Overview:**  \n",
      "Stanford's Graduate School of Business offers an MBA program that emphasizes innovation and technology management. This program is ideal for technical professionals looking to transition into leadership roles. The curriculum includes courses on strategic management, entrepreneurship, and operations, which are essential for leading technical teams in the aerospace industry.\n",
      "\n",
      "**Key Features:**\n",
      "- **Curriculum:** Offers courses in leadership, strategy, and technology management, tailored for those in technical fields.\n",
      "- **Research Opportunities:** Access to interdisciplinary projects and initiatives, including the Stanford Technology Ventures Program (STVP).\n",
      "- **Industry Connections:** Strong connections with Silicon Valley and the aerospace industry, providing networking opportunities with leaders in the field.\n",
      "- **Alumni Network:** A powerful alumni network that includes influential figures in technology and aerospace, facilitating mentorship and career opportunities.\n",
      "\n",
      "### Complementary Nature of the Programs\n",
      "- **Technical and Leadership Balance:** The Aerospace Engineering program provides the technical depth needed for understanding complex aerospace systems, while the MBA focuses on leadership, management, and strategic thinking.\n",
      "- **Interdisciplinary Collaboration:** Both programs encourage collaboration across disciplines, allowing you to apply technical knowledge in a business context, which is crucial for leadership roles.\n",
      "- **Networking Opportunities:** Together, these programs offer extensive networking opportunities with industry leaders, enhancing your visibility and career prospects in the aerospace sector.\n",
      "\n",
      "By pursuing these two Master's programs, you will be well-equipped to take on a technical leadership role at Boeing or similar organizations, combining deep technical knowledge with strong management and leadership skills.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## finalOutput ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## finalOutput ## ]]\n",
      "Based on your goal of becoming a technical leader at the Boeing Company, I recommend the following two Master's programs as the best complements:\n",
      "\n",
      "1. **Master of Science in Data Science from JHU**: This program will provide you with a strong foundation in data analysis, machine learning, and statistical modeling, which are essential skills for making data-driven decisions in the aerospace industry.\n",
      "2. **Master of Science in AI from JHU**: This program will equip you with advanced knowledge in artificial intelligence, including machine learning, deep learning, and natural language processing, which are critical for developing intelligent systems and making informed decisions in the aerospace sector.\n",
      "\n",
      "These two programs will provide you with a robust foundation in both technical expertise and leadership skills, making you a strong candidate for a technical leadership role at Boeing or similar organizations.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dspy.inspect_history(n=2)\n",
    "local_lm.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-14T00:04:44.951843]\u001b[0m\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "Please suggest two Master's programs that are highly complementary and can help an individual become a technical leader in the aerospace industry. The programs should be from top universities and have a strong reputation in the field. Consider factors such as curriculum, research opportunities, industry connections, and alumni network.\n",
      "\n",
      "Assume the individual has a strong background in a technical field and is looking to advance their career in a leadership role at Boeing Company or a similar organization.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32mTo become a technical leader in the aerospace industry, pursuing two complementary Master's programs can provide a robust foundation in both technical expertise and leadership skills. Here are two highly regarded programs from top universities that align well with your goals:\n",
      "\n",
      "### 1. Master of Science in Aerospace Engineering\n",
      "**University:** Massachusetts Institute of Technology (MIT)  \n",
      "**Program Overview:**  \n",
      "MIT's Department of Aeronautics and Astronautics offers a Master of Science in Aerospace Engineering that is renowned for its rigorous curriculum and cutting-edge research opportunities. The program covers advanced topics in aerodynamics, propulsion, structures, and systems engineering, providing a strong technical foundation. Students can engage in research projects that often collaborate with industry leaders, including Boeing.\n",
      "\n",
      "**Key Features:**\n",
      "- **Curriculum:** Focuses on advanced aerospace topics, systems engineering, and hands-on projects.\n",
      "- **Research Opportunities:** Access to state-of-the-art labs and facilities, with opportunities to work on projects related to space exploration, aircraft design, and more.\n",
      "- **Industry Connections:** Strong ties with leading aerospace companies, including Boeing, Lockheed Martin, and NASA.\n",
      "- **Alumni Network:** A vast and influential alumni network in the aerospace sector, providing valuable connections for career advancement.\n",
      "\n",
      "### 2. Master of Business Administration (MBA) with a focus on Technology Management\n",
      "**University:** Stanford University  \n",
      "**Program Overview:**  \n",
      "Stanford's Graduate School of Business offers an MBA program that emphasizes innovation and technology management. This program is ideal for technical professionals looking to transition into leadership roles. The curriculum includes courses on strategic management, entrepreneurship, and operations, which are essential for leading technical teams in the aerospace industry.\n",
      "\n",
      "**Key Features:**\n",
      "- **Curriculum:** Offers courses in leadership, strategy, and technology management, tailored for those in technical fields.\n",
      "- **Research Opportunities:** Access to interdisciplinary projects and initiatives, including the Stanford Technology Ventures Program (STVP).\n",
      "- **Industry Connections:** Strong connections with Silicon Valley and the aerospace industry, providing networking opportunities with leaders in the field.\n",
      "- **Alumni Network:** A powerful alumni network that includes influential figures in technology and aerospace, facilitating mentorship and career opportunities.\n",
      "\n",
      "### Complementary Nature of the Programs\n",
      "- **Technical and Leadership Balance:** The Aerospace Engineering program provides the technical depth needed for understanding complex aerospace systems, while the MBA focuses on leadership, management, and strategic thinking.\n",
      "- **Interdisciplinary Collaboration:** Both programs encourage collaboration across disciplines, allowing you to apply technical knowledge in a business context, which is crucial for leadership roles.\n",
      "- **Networking Opportunities:** Together, these programs offer extensive networking opportunities with industry leaders, enhancing your visibility and career prospects in the aerospace sector.\n",
      "\n",
      "By pursuing these two Master's programs, you will be well-equipped to take on a technical leadership role at Boeing or similar organizations, combining deep technical knowledge with strong management and leadership skills.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openai_lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(prompt_model=openai_lm, task_model=local_lm)\n",
    "optimizer = dspy.MIPROv2(metric=compute_overall_score, auto=\"medium\", num_threads=16, **models)\n",
    "\n",
    "kwargs = dict(minibatch_size=35, max_bootstrapped_demos=5, max_labeled_demos=0)\n",
    "opt_papillon = optimizer.compile(zeroshot, trainset=trainset, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
